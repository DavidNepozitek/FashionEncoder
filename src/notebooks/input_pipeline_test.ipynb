{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0  1  2  3]\n",
      "  [ 4  5  6  7]\n",
      "  [ 8  9 10 11]]\n",
      "\n",
      " [[12 13 14 15]\n",
      "  [16 17 18 19]\n",
      "  [20 21 22 23]]], shape=(2, 3, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0 0]\n",
      " [1 2]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[ 8  8  8  8]\n",
      "  [ 4  5  6  7]\n",
      "  [ 8  9 10 11]]\n",
      "\n",
      " [[12 13 14 15]\n",
      "  [16 17 18 19]\n",
      "  [ 9  9  9  9]]], shape=(2, 3, 4), dtype=int32)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import random\n",
    "from typing import Tuple\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "# test_tensor = tf.constant([1,2,3,0,1,1,0,3,3,0,0,0], shape=(2,2,3), dtype=\"float32\")\n",
    "# print(test_tensor)\n",
    "# indices = tf.constant([[0,0]])\n",
    "# updates = tf.constant([[9,9,9]], dtype=\"float32\")\n",
    "# test_tensor = tf.tensor_scatter_nd_update(test_tensor,indices,updates)\n",
    "# print(test_tensor)\n",
    "\n",
    "\n",
    "def parse_example(raw):\n",
    "    example = tf.io.parse_single_sequence_example(\n",
    "          raw, sequence_features={\n",
    "              \"categories\": tf.io.FixedLenSequenceFeature([], tf.int64),\n",
    "              \"features\": tf.io.FixedLenSequenceFeature(2048, tf.float32)\n",
    "          })\n",
    "    return example[1][\"features\"], example[1][\"categories\"]\n",
    "\n",
    "\n",
    "def get_dataset(filenames):\n",
    "    raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "    return raw_dataset.map(parse_example)\n",
    "\n",
    "\n",
    "def append_targets(features, categories, token_pos):\n",
    "    return (features, categories, token_pos), features\n",
    "\n",
    "\n",
    "def add_special_token_positions(features, categories):\n",
    "    seq_length = tf.shape(categories)[0]\n",
    "    random_position = tf.random.uniform((1,), minval=0, maxval=seq_length, dtype=\"int32\")\n",
    "    token_positions = tf.expand_dims(random_position, 0)\n",
    "    return features, categories, token_positions\n",
    "    \n",
    "    \n",
    "def get_training_dataset(filenames, batch_size):\n",
    "    outfits = get_dataset(filenames)\n",
    "    outfits = outfits.map(add_special_token_positions)\n",
    "    outfits = outfits.padded_batch(batch_size, ([None, 2048], [None], [None,1]))\n",
    "    return outfits.map(append_targets)\n",
    "\n",
    "\n",
    "def replace_slices(batch, batched_positions, updates):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        batch: Tensor of shape [batch_size, seq_length, feature_dim]\n",
    "        batched_positions: Tensor of shape [batch_size, None, 1] corresponding to indices of sequence\n",
    "        updates: Tensor of shape [total_number_of_indices, feature_dim]\n",
    "\n",
    "    Returns:\n",
    "        Tensor with the same shape as batch. Defined slices are replaced\n",
    "    \"\"\"\n",
    "    batch_size = tf.shape(batched_positions)[0]\n",
    "    r = tf.range(0, limit=batch_size, dtype=\"int32\")\n",
    "    r = tf.reshape(r, shape=[tf.shape(r)[0], -1, 1])\n",
    "    indices = tf.squeeze(tf.concat([r, batched_positions], axis=-1))\n",
    "    print(indices)\n",
    "    return tf.tensor_scatter_nd_update(batch, indices, updates)\n",
    "\n",
    "\n",
    "batch = tf.range(0, 24)\n",
    "batch = tf.reshape(batch, [2, 3, 4])\n",
    "b_pos = tf.constant([[[0]], [[2]]])\n",
    "up = tf.constant([[8, 8, 8, 8], [9, 9, 9, 9]])\n",
    "print(batch)\n",
    "res = replace_slices(batch, b_pos, up)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = get_training_dataset([\"output-000-5.tfrecord\"], 2)\n",
    "\n",
    "# for x, y in dataset:\n",
    "#     zeroes = tf.meshgrid(tf.range(tf.shape(x[0])[0]), tf.range(tf.shape(x[0])[0]))\n",
    "#     mask_positions = x[2]\n",
    "#     zero_slices = tf.gather_nd(zeroes, x[2], batch_dims=1)\n",
    "#     updates = tf.reshape(zero_slices, shape=(-1, 2048))\n",
    "#     print(x[2])\n",
    "#     r = tf.range(0, limit=tf.shape(x[2])[0], dtype=\"int32\")\n",
    "#     r = tf.reshape(r, shape=[r.shape[0], -1, 1])\n",
    "#     print(r)\n",
    "#     indices = tf.squeeze(tf.concat([r, x[2]], axis=-1))\n",
    "#     print(indices)\n",
    "#     # indices = tf.constant([[0,1], [1, 6]]) \n",
    "#     replaced = tf.tensor_scatter_nd_update(x[0], indices, updates)\n",
    "#     print(replaced)\n",
    "# \n",
    "#     r = tf.range(0, limit=tf.shape(mask_positions)[0], dtype=\"int64\")\n",
    "#     r = tf.reshape(r, shape=[tf.shape(r)[0], -1, 1])\n",
    "#     mask_positions = tf.cast(mask_positions, dtype=\"int64\")\n",
    "#     indices = tf.squeeze(tf.concat([r, mask_positions], axis=-1))\n",
    "#     weights = tf.sparse.to_dense(tf.SparseTensor(indices, 1, dense_shape=tf.cast(tf.shape(y), dtype=\"int64\")))\n",
    "#     weights = tf.reshape(weights, [-1])\n",
    "#     print(weights)\n",
    "    \n",
    "    \n",
    "    # r = tf.range(0, limit=tf.shape(mask_positions)[0])\n",
    "    # r = tf.reshape(r, shape=[tf.shape(r)[0], -1, 1])\n",
    "    # indices = tf.squeeze(tf.concat([r, mask_positions], axis=-1))\n",
    "    # print(indices)\n",
    "    # updates = tf.ones(shape=(tf.shape(mask_positions)[0]))\n",
    "    # print(updates)\n",
    "    # weights = tf.scatter_nd(indices, updates, tf.shape(x[1]))\n",
    "    # weights = tf.cast(weights, dtype=\"float32\")\n",
    "    # weights = tf.reshape(weights, [-1])\n",
    "    # length = tf.shape(weights)[0]\n",
    "    # weights = tf.tile(weights, [length])\n",
    "    # weights = tf.reshape(weights, [-1, length])\n",
    "    # weights = tf.transpose(weights)\n",
    "    # print(weights)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tf.Tensor([1. 0. 0. 0. 1. 0.], shape=(6,), dtype=float32)\n",
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.  1.  2.  3.]\n",
      " [ 4.  5.  6.  7.]\n",
      " [ 8.  9. 10. 11.]\n",
      " [12. 13. 14. 15.]\n",
      " [16. 17. 18. 19.]\n",
      " [20. 21. 22. 23.]], shape=(6, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[  14.   38.   62.   86.  110.  134.]\n",
      " [  38.  126.  214.  302.  390.  478.]\n",
      " [  62.  214.  366.  518.  670.  822.]\n",
      " [  86.  302.  518.  734.  950. 1166.]\n",
      " [ 110.  390.  670.  950. 1230. 1510.]\n",
      " [ 134.  478.  822. 1166. 1510. 1854.]], shape=(6, 6), dtype=float32)\n",
      "tf.Tensor([120. 352. 456. 432. 280.   0.], shape=(6,), dtype=float32)\n",
      "tf.Tensor(400.0, shape=(), dtype=float32)\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float32, numpy=200.0>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def xentropy_loss(y_pred, y_true, categories, mask_positions, acc=None):\n",
    "    feature_dim = y_pred.shape[2]\n",
    "\n",
    "    # Compute loss only from mask token\n",
    "    r = tf.range(0, limit=tf.shape(mask_positions)[0])\n",
    "    r = tf.reshape(r, shape=[tf.shape(r)[0], -1, 1])\n",
    "    indices = tf.squeeze(tf.concat([r, mask_positions], axis=-1))\n",
    "    updates = tf.ones(shape=(tf.shape(mask_positions)[0]))\n",
    "    weights = tf.scatter_nd(indices, updates, tf.shape(categories))\n",
    "    weights = tf.cast(weights, dtype=\"float32\")\n",
    "    weights = tf.reshape(weights, [-1])\n",
    "    weights_sum = tf.reduce_sum(weights)\n",
    "    print(weights)\n",
    "    print(weights_sum)\n",
    "\n",
    "    # Reshape to batch (size * seq length, feature dim)\n",
    "    pred_batch = tf.reshape(y_pred, [-1, feature_dim])\n",
    "    true_batch = tf.reshape(y_true, [-1, feature_dim])\n",
    "    item_count = true_batch.shape[0]\n",
    "    print(pred_batch)\n",
    "\n",
    "    # Dot product of every prediction with all labels\n",
    "    logits = tf.matmul(pred_batch, true_batch, transpose_b=True)\n",
    "    print(logits)\n",
    "    \n",
    "    # One-hot labels (the indentity matrix)\n",
    "    labels = tf.eye(item_count, item_count)\n",
    "\n",
    "    # Compute weights to identify padding values\n",
    "    # not_padded = tf.equal(true_batch, 0)\n",
    "    # not_padded = tf.reduce_all(not_padded, axis=1)\n",
    "    # not_padded = tf.math.logical_not(not_padded)\n",
    "    # not_padded = tf.cast(not_padded, dtype=\"float32\")\n",
    "    # items_in_batch = tf.reduce_sum(not_padded)\n",
    "\n",
    "    if acc is not None:\n",
    "        acc(labels, logits, sample_weight=weights)\n",
    "\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "    print(cross_entropy)\n",
    "    cross_entropy = tf.tensordot(cross_entropy, weights, 1)\n",
    "    print(cross_entropy)\n",
    "    return tf.reduce_sum(cross_entropy) / weights_sum\n",
    "\n",
    "acc = tf.keras.metrics.CategoricalAccuracy()\n",
    "batch = tf.range(0, 24, dtype=\"float32\")\n",
    "batch_pred = tf.reshape(batch, [2, 3, 4])\n",
    "cat = tf.zeros(shape=[2,3], dtype=\"float32\")\n",
    "b_pos = tf.constant([[[0]], [[1]]])\n",
    "\n",
    "xentropy_loss(batch_pred, batch_pred, cat, b_pos,acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}