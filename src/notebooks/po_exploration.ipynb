{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Total 12 groups.\n",
      "Total 224 categories.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import sys\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cat_file = r\"D:\\David\\Škola\\RP\\dataset\\polyvore_outfits\\categories.csv\"\n",
    "\n",
    "with open(cat_file) as categories:\n",
    "    csv_reader = csv.reader(categories, delimiter=',')\n",
    "    line_count = 0\n",
    "    cat_groups = []\n",
    "    cat_dict = {}\n",
    "    for row in csv_reader:\n",
    "            cat_number, cat, cat_group = row\n",
    "            if cat_group.strip() not in cat_groups:\n",
    "                cat_groups.append(cat_group.strip())\n",
    "                \n",
    "            cat_dict[int(cat_number)] = cat_group.strip()\n",
    "                \n",
    "            line_count += 1\n",
    "        \n",
    "    print(f'Total {len(cat_groups)} groups.')\n",
    "    print(f'Total {line_count} categories.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Loaded 16995 outfits from D:\\David\\Škola\\RP\\dataset\\polyvore_outfits\\disjoint\\train.json\n",
      "count    16995.000000\n",
      "mean         5.056487\n",
      "std          1.479326\n",
      "min          2.000000\n",
      "25%          4.000000\n",
      "50%          5.000000\n",
      "75%          6.000000\n",
      "max         16.000000\n",
      "dtype: float64\n",
      "{2: 346, 3: 1842, 4: 4178, 5: 4850, 6: 3208, 7: 1581, 8: 639, 9: 231, 10: 90, 11: 18, 12: 9, 13: 1, 14: 1, 16: 1}\n",
      "Loaded 71967 items from D:\\David\\Škola\\RP\\dataset\\polyvore_outfits\\disjoint\\train.json\n",
      "Loaded 3000 outfits from D:\\David\\Škola\\RP\\dataset\\polyvore_outfits\\disjoint\\valid.json\n",
      "count    3000.000000\n",
      "mean        5.096000\n",
      "std         1.485099\n",
      "min         2.000000\n",
      "25%         4.000000\n",
      "50%         5.000000\n",
      "75%         6.000000\n",
      "max        14.000000\n",
      "dtype: float64\n",
      "{2: 52, 3: 316, 4: 722, 5: 866, 6: 568, 7: 302, 8: 107, 9: 45, 10: 11, 11: 9, 12: 1, 14: 1}\n",
      "Loaded 14657 items from D:\\David\\Škola\\RP\\dataset\\polyvore_outfits\\disjoint\\valid.json\n",
      "Loaded 15145 outfits from D:\\David\\Škola\\RP\\dataset\\polyvore_outfits\\disjoint\\test.json\n",
      "count    15145.000000\n",
      "mean         4.903400\n",
      "std          1.646838\n",
      "min          2.000000\n",
      "25%          4.000000\n",
      "50%          5.000000\n",
      "75%          6.000000\n",
      "max         14.000000\n",
      "dtype: float64\n",
      "{2: 754, 3: 2309, 4: 3493, 5: 3663, 6: 2538, 7: 1350, 8: 662, 9: 248, 10: 89, 11: 28, 12: 8, 13: 2, 14: 1}\n",
      "Loaded 70035 items from D:\\David\\Škola\\RP\\dataset\\polyvore_outfits\\disjoint\\test.json\n",
      "{2: 1152, 3: 4467, 4: 8393, 5: 9379, 6: 6314, 7: 3233, 8: 1408, 9: 524, 10: 190, 11: 55, 12: 18, 13: 3, 14: 3, 16: 1}\n",
      "Counter({'shoes': 0.9410643141718839, 'bags': 0.839954467842914, 'jewellery': 0.7908366533864541, 'tops': 0.6210870802504269, 'bottoms': 0.5605008537279453, 'all-body': 0.3708594194649972, 'outerwear': 0.3165623221400114, 'sunglasses': 0.2308764940239044, 'accessories': 0.12103016505406944, 'hats': 0.11758679567444508, 'scarves': 0.08352305065452476})\n",
      "The dataset contains 35140 outfits\n",
      "The dataset contains 152785 items\n",
      "The metadata contains 251008 items\n",
      "The metadata contains 153 categories\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "dataset_path_train = r\"D:\\David\\Škola\\RP\\dataset\\polyvore_outfits\\disjoint\\train.json\"\n",
    "dataset_path_valid = r\"D:\\David\\Škola\\RP\\dataset\\polyvore_outfits\\disjoint\\valid.json\"\n",
    "dataset_path_test = r\"D:\\David\\Škola\\RP\\dataset\\polyvore_outfits\\disjoint\\test.json\"\n",
    "fitb_filepath = r\"D:\\David\\Škola\\RP\\dataset\\polyvore_outfits\\disjoint\\fill_in_blank_valid.json\"\n",
    "dataset_root = r\"D:\\David\\Škola\\RP\\dataset\\polyvore_outfits\"\n",
    "\n",
    "def key_from_fitb_string(string):\n",
    "    values = string.split(\"_\")\n",
    "    return int(values[0]), int(values[1])\n",
    "\n",
    "with open(Path(dataset_root, \"polyvore_item_metadata.json\")) as json_file:\n",
    "    metadata = json.load(json_file)\n",
    "    \n",
    "compositions = []\n",
    "\n",
    "def get_sets(dataset_path):\n",
    "    item_counts = []\n",
    "    with open(dataset_path) as json_file:\n",
    "        raw_json = json.load(json_file)\n",
    "        print(\"Loaded \" + str(len(raw_json)) + \" outfits from \" + dataset_path, flush=True)\n",
    "        items_set = set()\n",
    "        outfits_set = set()\n",
    "\n",
    "        # Load all test items into dict\n",
    "        for outfit in raw_json:\n",
    "            compositions.extend([metadata[item[\"item_id\"]][\"semantic_category\"] for item in outfit[\"items\"]])\n",
    "            set_id = int(outfit[\"set_id\"])\n",
    "            outfits_set.add(set_id)\n",
    "            item_counts.append(len(outfit[\"items\"]))\n",
    "            for item in outfit[\"items\"]:\n",
    "                items_set.add(item[\"item_id\"])\n",
    "    \n",
    "    series = pd.Series(item_counts)\n",
    "    print(series.describe())\n",
    "    bcounts = np.bincount(item_counts)\n",
    "    print(dict(zip(np.unique(item_counts), bcounts[bcounts.nonzero()])))\n",
    "    \n",
    "    print(\"Loaded \" + str(len(items_set)) + \" items from \" + dataset_path, flush=True)\n",
    "    return outfits_set, items_set, item_counts\n",
    "            \n",
    "train_o, train_i, train_counts = get_sets(dataset_path_train)\n",
    "valid_o, valid_i, valid_counts = get_sets(dataset_path_valid)\n",
    "test_o, test_i, test_counts = get_sets(dataset_path_test)\n",
    "\n",
    "total_o = train_o.union(valid_o).union(test_o)\n",
    "total_counts = train_counts\n",
    "total_counts.extend(valid_counts)\n",
    "total_counts.extend(test_counts)\n",
    "\n",
    "bcounts = np.bincount(total_counts)\n",
    "print(dict(zip(np.unique(total_counts), bcounts[bcounts.nonzero()])))\n",
    "\n",
    "outfits_count = len(total_o)\n",
    "counter = Counter(compositions)\n",
    "for cat in counter:\n",
    "    counter[cat] = counter[cat] / outfits_count\n",
    "print(counter)\n",
    "\n",
    "total_i = train_i.union(valid_i).union(test_i)\n",
    "print(\"The dataset contains \" + str(len(total_o)) + \" outfits\")\n",
    "print(\"The dataset contains \" + str(len(total_i)) + \" items\")\n",
    "print(\"The metadata contains \" + str(len(metadata)) + \" items\")\n",
    "\n",
    "categories = set()\n",
    "\n",
    "for item in metadata.values():\n",
    "    categories.add(int(item[\"category_id\"]))\n",
    "print(\"The metadata contains \" + str(len(categories)) + \" categories\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "examples = []\n",
    "with open(fitb_filepath) as fitb_file:\n",
    "    raw_json = json.load(fitb_file)\n",
    "    print(\"Loaded \" + str(len(raw_json)) + \" questions\", flush=True)\n",
    "\n",
    "    # Compose questions from FITB file and test items dict\n",
    "    for task in raw_json:\n",
    "        set_id = None\n",
    "        inputs = []\n",
    "        input_categories = []\n",
    "        targets = []\n",
    "        target_categories = []\n",
    "        target_pos = None\n",
    "\n",
    "        for question_item_str in task[\"question\"]:\n",
    "            q_key = key_from_fitb_string(question_item_str)\n",
    "            item_category = items[q_key]\n",
    "            input_categories.append(item_category)\n",
    "            set_id = q_key[0]\n",
    "        pos = 0\n",
    "\n",
    "        for question_item_str in task[\"answers\"]:\n",
    "            q_key = key_from_fitb_string(question_item_str)\n",
    "            if q_key[0] == set_id:\n",
    "                target_pos = pos\n",
    "            item_category = items[q_key]\n",
    "            target_categories.append(item_category)\n",
    "            pos += 1\n",
    "        \n",
    "        if len(set(target_categories)) > 1:\n",
    "            print(set_id)\n",
    "            print(target_categories)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}