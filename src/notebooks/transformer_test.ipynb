{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import models.transformer.fashion_transformer as fashion_t\n",
    "import models.transformer.fashion_encoder as fashion_enc\n",
    "import official.transformer.v2.misc as misc\n",
    "import importlib\n",
    "import tensorflow as tf\n",
    "import src.models.transformer.metrics as metrics\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "importlib.reload(fashion_enc)\n",
    "\n",
    "params = {\n",
    "        \"feature_dim\": 2048,\n",
    "        \"dtype\": \"float32\",\n",
    "        \"hidden_size\": 512,\n",
    "        \"extra_decode_length\": 0,\n",
    "        \"num_hidden_layers\": 1,\n",
    "        \"num_heads\": 2,\n",
    "        \"max_length\": 10,\n",
    "        \"filter_size\": 1024,\n",
    "        \"layer_postprocess_dropout\": 0.1,\n",
    "        \"attention_dropout\": 0.1,\n",
    "        \"relu_dropout\": 0.1,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"with_cnn\": True,\n",
    "        \"masking_mode\": \"single-token\"\n",
    "    }\n",
    "\n",
    "# model = fashion_enc.create_model(params, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[[0.31860483 0.36392343 0.80741155 0.5911     0.63173854 0.05812967\n",
      "  0.32208538 0.14309645 0.8284503  0.8803594  0.06734312 0.05356216\n",
      "  0.22021437 0.4388162  0.5581455  0.03147018 0.55408883 0.75319207\n",
      "  0.24212945 0.57994854 0.97491944 0.7997544  0.667215   0.48745024\n",
      "  0.22272313]\n",
      " [0.34753466 0.60360205 0.6928375  0.47277737 0.631305   0.8939159\n",
      "  0.85317886 0.9457749  0.5062498  0.17569292 0.917397   0.09534752\n",
      "  0.602227   0.9700693  0.17403913 0.34018946 0.24578941 0.40479517\n",
      "  0.6518483  0.71281207 0.7945384  0.3933773  0.44591975 0.9607481\n",
      "  0.79610074]\n",
      " [0.06626034 0.3911413  0.8191577  0.5019227  0.04697287 0.03171968\n",
      "  0.26968932 0.04560208 0.8048042  0.9430913  0.5896473  0.7252965\n",
      "  0.23746777 0.7953969  0.28319836 0.26671016 0.85031366 0.5714973\n",
      "  0.36249077 0.8949276  0.9579139  0.11332095 0.17376733 0.5915103\n",
      "  0.3368503 ]\n",
      " [0.15532422 0.10206866 0.86086655 0.33319795 0.8145702  0.85729766\n",
      "  0.05001223 0.34753203 0.3500985  0.95510197 0.6488613  0.76697946\n",
      "  0.2766564  0.3786608  0.14054823 0.71296346 0.7077228  0.21963108\n",
      "  0.9172002  0.46577978 0.47595608 0.12477779 0.9921279  0.35163546\n",
      "  0.37685263]\n",
      " [0.15972793 0.44042063 0.11962962 0.04555655 0.07398987 0.79512286\n",
      "  0.24364197 0.30375648 0.996513   0.6815318  0.40814912 0.7723701\n",
      "  0.12585473 0.24180746 0.5521542  0.4961214  0.5590378  0.07952797\n",
      "  0.9219247  0.21315992 0.22265029 0.02979517 0.27308118 0.82261\n",
      "  0.04693055]], shape=(5, 25), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.34753466 0.60360205 0.6928375  0.47277737 0.631305   0.8939159\n",
      "  0.85317886 0.9457749  0.5062498  0.17569292 0.917397   0.09534752\n",
      "  0.602227   0.9700693  0.17403913 0.34018946 0.24578941 0.40479517\n",
      "  0.6518483  0.71281207 0.7945384  0.3933773  0.44591975 0.9607481\n",
      "  0.79610074]\n",
      " [0.06626034 0.3911413  0.8191577  0.5019227  0.04697287 0.03171968\n",
      "  0.26968932 0.04560208 0.8048042  0.9430913  0.5896473  0.7252965\n",
      "  0.23746777 0.7953969  0.28319836 0.26671016 0.85031366 0.5714973\n",
      "  0.36249077 0.8949276  0.9579139  0.11332095 0.17376733 0.5915103\n",
      "  0.3368503 ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.15972793 0.44042063 0.11962962 0.04555655 0.07398987 0.79512286\n",
      "  0.24364197 0.30375648 0.996513   0.6815318  0.40814912 0.7723701\n",
      "  0.12585473 0.24180746 0.5521542  0.4961214  0.5590378  0.07952797\n",
      "  0.9219247  0.21315992 0.22265029 0.02979517 0.27308118 0.82261\n",
      "  0.04693055]], shape=(5, 25), dtype=float32)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# input_batch = tf.random.uniform(shape=(3,5,25))\n",
    "# \n",
    "# np_array = input_batch.numpy()\n",
    "# batch_size = np_array.shape[0]\n",
    "# \n",
    "# for i in range(batch_size):\n",
    "#     print(np_array[i])\n",
    "\n",
    "input_batch = tf.random.uniform(shape=(5,25))\n",
    "mask = tf.constant([[0],[1],[1],[0],[1]], dtype=\"float32\")\n",
    "mask = tf.tile(mask, [1, 25])\n",
    "mask = tf.transpose(mask)\n",
    "masked = tf.tensordot(input_batch, mask, 1)\n",
    "# print(masked)\n",
    "\n",
    "input_batch = tf.random.uniform(shape=(5,25))\n",
    "print(input_batch)\n",
    "mask = tf.zeros(shape=(5,5))\n",
    "mask = tf.linalg.set_diag(mask, [0,1,1,0,1])\n",
    "masked = tf.einsum(\"ij,jk->ik\", mask, input_batch)\n",
    "print(masked)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Before dense\n",
      "(None, None, 2048)\n",
      "After dense\n",
      "(None, None, 512)\n",
      "Model: \"transformer_v2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, None, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 2048)        1050624   \n",
      "_________________________________________________________________\n",
      "encoder_stack_9 (EncoderStac (None, None, 512)         2101760   \n",
      "=================================================================\n",
      "Total params: 4,201,472\n",
      "Trainable params: 4,201,472\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, None, 2048)]      0         \n",
      "_________________________________________________________________\n",
      "transformer_v2 (FashionEncod (None, None, 2048)        4201472   \n",
      "=================================================================\n",
      "Total params: 4,201,472\n",
      "Trainable params: 4,201,472\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "importlib.reload(fashion_enc)\n",
    "\n",
    "params = misc.get_model_params(\"base\", 1)\n",
    "\n",
    "params.update({\n",
    "    \"feature_dim\": 2048,\n",
    "    \"dtype\": \"float32\",\n",
    "    \"hidden_size\": 512,\n",
    "    \"extra_decode_length\": 0,\n",
    "    \"num_hidden_layers\": 1,\n",
    "    \"num_heads\": 2,\n",
    "    \"max_length\": 10,\n",
    "    \"default_batch_size\": 128,\n",
    "    \"filter_size\": 1024\n",
    "})\n",
    "\n",
    "model = fashion_enc.create_model(params, False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(3, 2, 2048)\n",
      "[[[5.3061867e-01 0.0000000e+00 0.0000000e+00 ... 9.8705864e-01\n",
      "   3.0908227e-02 0.0000000e+00]\n",
      "  [8.4564286e-01 0.0000000e+00 0.0000000e+00 ... 1.5424176e+00\n",
      "   3.2188863e-01 0.0000000e+00]]\n",
      "\n",
      " [[7.1251291e-01 3.5658669e-01 0.0000000e+00 ... 1.1799755e+00\n",
      "   9.2774630e-05 0.0000000e+00]\n",
      "  [1.1838869e+00 7.3470104e-01 0.0000000e+00 ... 1.3230802e+00\n",
      "   0.0000000e+00 0.0000000e+00]]\n",
      "\n",
      " [[7.9162467e-01 3.8026094e-01 0.0000000e+00 ... 9.5547354e-01\n",
      "   7.4496865e-02 0.0000000e+00]\n",
      "  [0.0000000e+00 5.8710259e-01 0.0000000e+00 ... 1.4925238e+00\n",
      "   0.0000000e+00 0.0000000e+00]]]\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, None, 2048)]      0         \n",
      "_________________________________________________________________\n",
      "transformer_v2 (FashionEncod (None, None, 2048)        4201472   \n",
      "=================================================================\n",
      "Total params: 4,201,472\n",
      "Trainable params: 4,201,472\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "input_batch = tf.random.uniform(shape=(3,2,2048))\n",
    "output = model.predict_on_batch(input_batch)\n",
    "print(output.shape)\n",
    "print(output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "inputs\n",
      "(None, None, 2048)\n",
      "attention_bias\n",
      "(None, 1, 1, None)\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d2163c3074d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m })\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfashion_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\David\\Škola\\outfit-generation\\src\\models\\transformer\\fashion_transformer.py\u001b[0m in \u001b[0;36mcreate_model\u001b[1;34m(params, is_train)\u001b[0m\n\u001b[0;32m     62\u001b[0m       \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"feature_dim\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"inputs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m       \u001b[0minternal_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFashionTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"transformer_v2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minternal_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m       \u001b[0minternal_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[1;31m# outputs, scores = ret[\"outputs\"], ret[\"scores\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    840\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[0;32m    841\u001b[0m                   \u001b[1;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m                     \u001b[1;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m                     \u001b[1;31m# circular dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in converted code:\n    relative to D:\\:\n\n    avid\\Škola\\outfit-generation\\src\\models\\transformer\\fashion_transformer.py:150 call  *\n        encoder_outputs = self.encode(inputs, attention_bias, training)\n    avid\\Škola\\outfit-generation\\src\\models\\transformer\\fashion_transformer.py:195 encode  *\n        return self.encoder_stack(\n    rogramy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:842 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    avid\\Škola\\outfit-generation\\src\\models\\transformer\\fashion_transformer.py:518 call  *\n        encoder_inputs = self_attention_layer(\n    rogramy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:842 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    avid\\Škola\\outfit-generation\\src\\models\\transformer\\fashion_transformer.py:453 call  *\n        return x + y\n    rogramy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py:899 binary_op_wrapper\n        return func(x, y, name=name)\n    rogramy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py:1197 _add_dispatch\n        return gen_math_ops.add_v2(x, y, name=name)\n    rogramy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py:549 add_v2\n        \"AddV2\", x=x, y=y, name=name)\n    rogramy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py:793 _apply_op_helper\n        op_def=op_def)\n    rogramy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py:548 create_op\n        compute_device)\n    rogramy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:3429 _create_op_internal\n        op_def=op_def)\n    rogramy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1773 __init__\n        control_input_ops)\n    rogramy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1613 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 2048 and 512 for 'transformer_v2_1/Transformer/encode/encoder_stack_1/layer_0/self_attention/pre_post_processing_wrapper_5/add' (op: 'AddV2') with input shapes: [?,?,2048], [?,?,512].\n"
     ],
     "ename": "ValueError",
     "evalue": "in converted code:\n    relative to D:\\:\n\n    avid\\Škola\\outfit-generation\\src\\models\\transformer\\fashion_transformer.py:150 call  *\n        encoder_outputs = self.encode(inputs, attention_bias, training)\n    avid\\Škola\\outfit-generation\\src\\models\\transformer\\fashion_transformer.py:195 encode  *\n        return self.encoder_stack(\n    rogramy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:842 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    avid\\Škola\\outfit-generation\\src\\models\\transformer\\fashion_transformer.py:518 call  *\n        encoder_inputs = self_attention_layer(\n    rogramy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py:842 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    avid\\Škola\\outfit-generation\\src\\models\\transformer\\fashion_transformer.py:453 call  *\n        return x + y\n    rogramy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py:899 binary_op_wrapper\n        return func(x, y, name=name)\n    rogramy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py:1197 _add_dispatch\n        return gen_math_ops.add_v2(x, y, name=name)\n    rogramy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py:549 add_v2\n        \"AddV2\", x=x, y=y, name=name)\n    rogramy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py:793 _apply_op_helper\n        op_def=op_def)\n    rogramy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py:548 create_op\n        compute_device)\n    rogramy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:3429 _create_op_internal\n        op_def=op_def)\n    rogramy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1773 __init__\n        control_input_ops)\n    rogramy\\Anaconda3\\envs\\outfit-generation\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1613 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 2048 and 512 for 'transformer_v2_1/Transformer/encode/encoder_stack_1/layer_0/self_attention/pre_post_processing_wrapper_5/add' (op: 'AddV2') with input shapes: [?,?,2048], [?,?,512].\n",
     "output_type": "error"
    }
   ],
   "source": [
    "importlib.reload(fashion_t)\n",
    "\n",
    "params = misc.get_model_params(\"base\", 1)\n",
    "\n",
    "params.update({\n",
    "    \"feature_dim\": 2048,\n",
    "    \"dtype\": \"float32\",\n",
    "    \"hidden_size\": 512,\n",
    "    \"extra_decode_length\": 0,\n",
    "    \"num_hidden_layers\": 1,\n",
    "    \"num_heads\": 2,\n",
    "    \"max_length\": 10,\n",
    "    \"default_batch_size\": 128,\n",
    "    \"filter_size\": 1024\n",
    "})\n",
    "\n",
    "model = fashion_t.create_model(params, False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 8, 256)\n",
      "[[[ 0.3721342   0.7154289  -0.06266356 ...  0.7965158  -0.33333158\n",
      "   -0.73048675]\n",
      "  [ 0.3721342   0.7154289  -0.06266356 ...  0.7965158  -0.33333158\n",
      "   -0.73048675]\n",
      "  [ 0.3721342   0.7154289  -0.06266356 ...  0.7965158  -0.33333158\n",
      "   -0.73048675]\n",
      "  ...\n",
      "  [ 0.3721342   0.7154289  -0.06266356 ...  0.7965158  -0.33333158\n",
      "   -0.73048675]\n",
      "  [ 0.3721342   0.7154289  -0.06266356 ...  0.7965158  -0.33333158\n",
      "   -0.73048675]\n",
      "  [ 0.3721342   0.7154289  -0.06266356 ...  0.7965158  -0.33333158\n",
      "   -0.73048675]]\n",
      "\n",
      " [[ 0.80776685  0.04199074 -1.3678492  ...  0.13974936 -1.3057268\n",
      "   -1.5029002 ]\n",
      "  [ 0.80776685  0.04199074 -1.3678492  ...  0.13974936 -1.3057268\n",
      "   -1.5029002 ]\n",
      "  [ 0.80776685  0.04199074 -1.3678492  ...  0.13974936 -1.3057268\n",
      "   -1.5029002 ]\n",
      "  ...\n",
      "  [ 0.80776685  0.04199074 -1.3678492  ...  0.13974936 -1.3057268\n",
      "   -1.5029002 ]\n",
      "  [ 0.80776685  0.04199074 -1.3678492  ...  0.13974936 -1.3057268\n",
      "   -1.5029002 ]\n",
      "  [ 0.80776685  0.04199074 -1.3678492  ...  0.13974936 -1.3057268\n",
      "   -1.5029002 ]]\n",
      "\n",
      " [[ 0.14748147 -0.36441964 -0.27014762 ...  0.7890442  -0.06206196\n",
      "   -1.3667493 ]\n",
      "  [ 0.14748147 -0.36441964 -0.27014762 ...  0.7890442  -0.06206196\n",
      "   -1.3667493 ]\n",
      "  [ 0.14748147 -0.36441964 -0.27014762 ...  0.7890442  -0.06206196\n",
      "   -1.3667493 ]\n",
      "  ...\n",
      "  [ 0.14748147 -0.36441964 -0.27014762 ...  0.7890442  -0.06206196\n",
      "   -1.3667493 ]\n",
      "  [ 0.14748147 -0.36441964 -0.27014762 ...  0.7890442  -0.06206196\n",
      "   -1.3667493 ]\n",
      "  [ 0.14748147 -0.36441964 -0.27014762 ...  0.7890442  -0.06206196\n",
      "   -1.3667493 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.0192876   0.21019636 -0.18677343 ...  0.64026356 -0.37289396\n",
      "   -0.9723649 ]\n",
      "  [ 1.0192876   0.21019636 -0.18677343 ...  0.64026356 -0.37289396\n",
      "   -0.9723649 ]\n",
      "  [ 1.0192876   0.21019636 -0.18677343 ...  0.64026356 -0.37289396\n",
      "   -0.9723649 ]\n",
      "  ...\n",
      "  [ 1.0192876   0.21019636 -0.18677343 ...  0.64026356 -0.37289396\n",
      "   -0.9723649 ]\n",
      "  [ 1.0192876   0.21019636 -0.18677343 ...  0.64026356 -0.37289396\n",
      "   -0.9723649 ]\n",
      "  [ 1.0192876   0.21019636 -0.18677343 ...  0.64026356 -0.37289396\n",
      "   -0.9723649 ]]\n",
      "\n",
      " [[ 1.2259098   0.29313236 -0.3420076  ...  1.1623456  -1.1464028\n",
      "   -1.2901442 ]\n",
      "  [ 1.2259098   0.29313236 -0.3420076  ...  1.1623456  -1.1464028\n",
      "   -1.2901442 ]\n",
      "  [ 1.2259098   0.29313236 -0.3420076  ...  1.1623456  -1.1464028\n",
      "   -1.2901442 ]\n",
      "  ...\n",
      "  [ 1.2259098   0.29313236 -0.3420076  ...  1.1623456  -1.1464028\n",
      "   -1.2901442 ]\n",
      "  [ 1.2259098   0.29313236 -0.3420076  ...  1.1623456  -1.1464028\n",
      "   -1.2901442 ]\n",
      "  [ 1.2259098   0.29313236 -0.3420076  ...  1.1623456  -1.1464028\n",
      "   -1.2901442 ]]\n",
      "\n",
      " [[ 0.9590468  -0.12537736 -0.96861875 ...  0.94336456 -1.4756229\n",
      "   -0.95777786]\n",
      "  [ 0.9590468  -0.12537736 -0.96861875 ...  0.94336456 -1.4756229\n",
      "   -0.95777786]\n",
      "  [ 0.9590468  -0.12537736 -0.96861875 ...  0.94336456 -1.4756229\n",
      "   -0.95777786]\n",
      "  ...\n",
      "  [ 0.9590468  -0.12537736 -0.96861875 ...  0.94336456 -1.4756229\n",
      "   -0.95777786]\n",
      "  [ 0.9590468  -0.12537736 -0.96861875 ...  0.94336456 -1.4756229\n",
      "   -0.95777786]\n",
      "  [ 0.9590468  -0.12537736 -0.96861875 ...  0.94336456 -1.4756229\n",
      "   -0.95777786]]]\n"
     ]
    }
   ],
   "source": [
    "input_batch = tf.random.uniform(shape=(25,8,256))\n",
    "\n",
    "output = model.predict_on_batch(input_batch)\n",
    "\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[[[1. 2. 3.]\n",
      "  [0. 1. 1.]]\n",
      "\n",
      " [[0. 3. 3.]\n",
      "  [0. 0. 0.]]], shape=(2, 2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[False False False]\n",
      "  [ True False False]]\n",
      "\n",
      " [[ True False False]\n",
      "  [ True  True  True]]], shape=(2, 2, 3), dtype=bool)\n",
      "tf.Tensor(\n",
      "[[False False]\n",
      " [False  True]], shape=(2, 2), dtype=bool)\n",
      "tf.Tensor(\n",
      "[[ True  True]\n",
      " [ True False]], shape=(2, 2), dtype=bool)\n",
      "tf.Tensor(\n",
      "[[1 1]\n",
      " [1 0]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Dimension reduction before padding\n",
    "\n",
    "#tensorflow Shape (batch, input_length, feature_dim)\n",
    "test_tensor = tf.constant([1,2,3,0,1,1,0,3,3,0,0,0], shape=(2,2,3), dtype=\"float32\")\n",
    "print(test_tensor)\n",
    "test_tensor = tf.equal(test_tensor,0)\n",
    "print(test_tensor)\n",
    "test_tensor = tf.reduce_all(test_tensor, axis=2)\n",
    "print(test_tensor)\n",
    "test_tensor = tf.math.logical_not(test_tensor)\n",
    "print(test_tensor)\n",
    "test_tensor = tf.cast(test_tensor, dtype=\"int32\")\n",
    "print(test_tensor)\n",
    "test_tensor = tf.reduce_sum(test_tensor)\n",
    "print(test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tf.Tensor(0.25, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2857143, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5, shape=(), dtype=float32)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "importlib.reload(metrics)\n",
    "\n",
    "acc = tf.metrics.CategoricalAccuracy()\n",
    "\n",
    "#tensorflow Shape (batch, input_length, feature_dim)\n",
    "pred = tf.constant([1,2,3,0,1,1,0,3,3,0,0,1], shape=(2,2,3), dtype=\"float32\")\n",
    "true = tf.constant([1,2,3,0,1,1,0,3,3,0,2,0], shape=(2,2,3), dtype=\"float32\")\n",
    "\n",
    "metrics.categorical_acc(pred,true, acc)\n",
    "\n",
    "print(acc.result())\n",
    "\n",
    "pred = tf.constant([1,2,3,0,1,1,0,3,3,0,0,0], shape=(2,2,3), dtype=\"float32\")\n",
    "true = tf.constant([1,2,3,0,1,1,0,3,3,0,0,0], shape=(2,2,3), dtype=\"float32\")\n",
    "\n",
    "metrics.categorical_acc(pred,true, acc)\n",
    "\n",
    "print(acc.result())\n",
    "\n",
    "pred = tf.constant([1,0,0,0,0,1,0,3,0,0,0,0], shape=(2,2,3), dtype=\"float32\")\n",
    "true = tf.constant([1,0,0,0,0,1,0,3,0,0,0,0], shape=(2,2,3), dtype=\"float32\")\n",
    "\n",
    "metrics.categorical_acc(pred,true, acc)\n",
    "\n",
    "print(acc.result())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Assign test\n",
    "test_tensor = tf.constant([1,2,3,0,1,1,0,3,3,0,0,0], shape=(2,2,3), dtype=\"float32\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}