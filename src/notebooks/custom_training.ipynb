{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "import models.transformer.fashion_encoder as fashion_enc\n",
    "import official.transformer.v2.misc as misc\n",
    "import models.transformer.metrics as metrics\n",
    "import importlib\n",
    "\n",
    "def parse_example(raw):\n",
    "    example = tf.io.parse_single_sequence_example(\n",
    "          raw, sequence_features= {\n",
    "              \"categories\": tf.io.FixedLenSequenceFeature([], tf.int64),\n",
    "              \"features\": tf.io.FixedLenSequenceFeature(2048,tf.float32)\n",
    "          })\n",
    "    return example[1][\"features\"]\n",
    "\n",
    "def get_dataset():\n",
    "    filenames = [\"output-000-5.tfrecord\"]\n",
    "    raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "    return raw_dataset.map(parse_example)\n",
    "\n",
    "def duplicate(example):\n",
    "    return example, example\n",
    "    \n",
    "def loss(y_pred, y_true):\n",
    "    # Dot product for whole batch\n",
    "    res = tf.math.multiply(y_pred, y_true)\n",
    "    res = tf.math.reduce_sum(res)\n",
    "    return res\n",
    "\n",
    "def xentropy_loss(y_pred, y_true):\n",
    "    feature_dim = y_pred.shape[2]\n",
    "    # Reshape to batch (size * seq length, feature dim)\n",
    "    pred_batch = tf.reshape(y_pred, [-1, feature_dim])\n",
    "    true_batch = tf.reshape(y_true, [-1, feature_dim])\n",
    "    item_count = true_batch.shape[0]\n",
    "    # Dot product of every prediction with all labels\n",
    "    logits = tf.matmul(pred_batch, true_batch, transpose_b=True)\n",
    "    # One-hot labels (the indentity matrix)\n",
    "    labels = tf.eye(item_count, item_count)\n",
    "    \n",
    "    return tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels, logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tf.Tensor(9.154351, shape=(), dtype=float32)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "a = tf.constant([[[0.25106466, 0.00863039, 0.77634084, 0.23125434, 0.39757788],\n",
    "  [0.82858,    0.44247448, 0.9647038,  0.31152928, 0.7297981 ]],\n",
    " [[0.8109468,  0.4998417,  0.31938195 ,0.03625381 ,0.92246723],\n",
    "  [0.03745341, 0.7016275,  0.58033264, 0.10916102, 0.7598084 ]],\n",
    " [[0.57786167, 0.48389828, 0.7559997 , 0.51311195, 0.3556137 ],\n",
    "  [0.06377017, 0.37903416, 0.69512844, 0.8320352 , 0.3528793 ]]])\n",
    "b = tf.constant([[[0.25106466, 0.00863039, 0.77634084, 0.23125434, 0.39757788],\n",
    "  [0.82858,    0.44247448, 0.9647038,  0.31152928, 0.7297981 ]],\n",
    " [[0.8109468,  0.4998417,  0.31938195 ,0.03625381 ,0.92246723],\n",
    "  [0.03745341, 0.7016275,  0.58033264, 0.10916102, 0.7598084 ]],\n",
    " [[0.57786167, 0.48389828, 0.7559997 , 0.51311195, 0.3556137 ],\n",
    "  [0.06377017, 0.37903416, 0.69512844, 0.8320352 , 0.3528793 ]]])\n",
    "\n",
    "# print(a)\n",
    "# print(b)\n",
    "l = xentropy_loss(a,b)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def grad(model: tf.keras.Model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = xentropy_loss(model(inputs, training=True), targets)\n",
    "  return loss_value, tape.gradient(loss_value, model.trainable_variables)   \n",
    "\n",
    "def train(num_epochs, train_dataset: tf.data.Dataset, model: tf.keras.Model, optimizer):\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
    "    train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "    batch_number = 1\n",
    "    \n",
    "    ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer,model=model)\n",
    "    manager = tf.train.CheckpointManager(ckpt, './logs/tf_ckpts', max_to_keep=3)\n",
    "    \n",
    "    if manager.latest_checkpoint:\n",
    "        print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "    else:\n",
    "        print(\"Initializing from scratch.\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "      epoch_loss_avg = tf.keras.metrics.Mean('epoch_loss')\n",
    "      train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "      # Training loop\n",
    "      for x, y in train_dataset:\n",
    "        # Optimize the model\n",
    "        loss_value, grads = grad(model, x, y)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "        ckpt.step.assign_add(1)\n",
    "        \n",
    "        # Track progress\n",
    "        epoch_loss_avg(loss_value)  # Add current batch loss\n",
    "        train_loss(loss_value)   \n",
    "        \n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', train_loss.result(), step=batch_number)\n",
    "        batch_number = batch_number + 1\n",
    "      with train_summary_writer.as_default():    \n",
    "        tf.summary.scalar('epoch_loss', epoch_loss_avg.result(), step=epoch)\n",
    "          \n",
    "      if epoch % 50 == 0:\n",
    "        print(\"Epoch {:03d}: Loss: {:.3f}\".format(epoch, epoch_loss_avg.result()))\n",
    "        save_path = manager.save()\n",
    "        print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\n",
    "            \n",
    "    print(batch_number)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Model: \"transformer_v2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_stack_2 (EncoderStac multiple                  20986880  \n",
      "=================================================================\n",
      "Total params: 20,986,880\n",
      "Trainable params: 20,986,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, None, 2048)]      0         \n",
      "_________________________________________________________________\n",
      "transformer_v2 (FashionEncod (None, None, 2048)        20986880  \n",
      "=================================================================\n",
      "Total params: 20,986,880\n",
      "Trainable params: 20,986,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "importlib.reload(fashion_enc)\n",
    "importlib.reload(metrics)\n",
    "batch_size = 2\n",
    "num_epoch = 2000\n",
    "params = misc.get_model_params(\"base\", 1)\n",
    "\n",
    "params.update({\n",
    "    \"feature_dim\": 2048,\n",
    "    \"dtype\": \"float32\",\n",
    "    \"hidden_size\": 2048,\n",
    "    \"extra_decode_length\": 0,\n",
    "    \"num_hidden_layers\": 1,\n",
    "    \"num_heads\": 2,\n",
    "    \"max_length\": 10,\n",
    "    \"default_batch_size\": 128,\n",
    "    \"filter_size\": 1024\n",
    "})\n",
    "\n",
    "model = fashion_enc.create_model(params, True)\n",
    "model.summary()\n",
    "\n",
    "# model.compile('adam')\n",
    "# \n",
    "# outfits = get_dataset()\n",
    "# outfits = outfits.map(duplicate)\n",
    "# outfits = outfits.padded_batch(batch_size, (params[\"max_length\"], 2048))\n",
    "# model.fit(outfits, callbacks=[tf.keras.callbacks.TensorBoard(), tf.keras.callbacks.ModelCheckpoint(\"./checkpoints/\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Initializing from scratch.\n",
      "Epoch 000: Loss: 15.888\n",
      "Saved checkpoint for step 2: ./logs/tf_ckpts\\ckpt-1\n",
      "Epoch 050: Loss: 69.599\n",
      "Saved checkpoint for step 52: ./logs/tf_ckpts\\ckpt-2\n",
      "Epoch 100: Loss: 33.691\n",
      "Saved checkpoint for step 102: ./logs/tf_ckpts\\ckpt-3\n",
      "Epoch 150: Loss: 115.017\n",
      "Saved checkpoint for step 152: ./logs/tf_ckpts\\ckpt-4\n",
      "201\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_epoch = 200\n",
    "optimizer = tf.optimizers.Adam()\n",
    "outfits = get_dataset()\n",
    "outfits = outfits.padded_batch(batch_size, (None, 2048))\n",
    "outfits = outfits.map(duplicate)\n",
    "\n",
    "train(num_epoch, outfits, model, optimizer)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}