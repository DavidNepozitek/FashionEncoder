{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import models.transformer.fashion_encoder as fashion_enc\n",
    "import official.transformer.v2.misc as misc\n",
    "import importlib\n",
    "\n",
    "def parse_example(raw):\n",
    "    example = tf.io.parse_single_sequence_example(\n",
    "          raw, sequence_features= {\n",
    "              \"categories\": tf.io.FixedLenSequenceFeature([], tf.int64),\n",
    "              \"features\": tf.io.FixedLenSequenceFeature(2048,tf.float32)\n",
    "          })\n",
    "    return example[1][\"features\"]\n",
    "\n",
    "def get_dataset():\n",
    "    filenames = [\"output-000-5.tfrecord\"]\n",
    "    raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "    return raw_dataset.map(parse_example)\n",
    "\n",
    "def loss(y_pred, y_true):\n",
    "    # Dot product for whole batch\n",
    "    res = tf.math.multiply(y_pred, y_true)\n",
    "    res = tf.math.reduce_sum(res)\n",
    "    return res\n",
    "\n",
    "def xentropy_loss(y_pred, y_true):\n",
    "    feature_dim = y_pred.shape[2]\n",
    "    # Reshape to batch (size * seq length, feature dim)\n",
    "    pred_batch = tf.reshape(y_pred, [-1, feature_dim])\n",
    "    true_batch = tf.reshape(y_true, [-1, feature_dim])\n",
    "    item_count = true_batch.shape[0]\n",
    "    # Dot product of every prediction with all labels\n",
    "    logits = tf.matmul(pred_batch, true_batch, transpose_b=True)\n",
    "    # One-hot labels (the indentity matrix)\n",
    "    labels = tf.eye(item_count, item_count)\n",
    "    \n",
    "    return tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels, logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[[0.8773598  1.322979   0.8309996  0.7933215  0.9962138  0.891647  ]\n",
      " [1.322979   2.4426377  1.8857194  1.4898481  1.8416088  1.4078786 ]\n",
      " [0.8309996  1.8857194  1.8617413  1.2712791  1.2985845  0.81886685]\n",
      " [0.7933215  1.4898481  1.2712791  1.4196948  1.1261005  1.0306814 ]\n",
      " [0.9962138  1.8416088  1.2985845  1.1261005  1.5293622  1.2981972 ]\n",
      " [0.891647   1.4078786  0.81886685 1.0306814  1.2981972  1.4477434 ]], shape=(6, 6), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]], shape=(6, 6), dtype=float32)\n",
      "tf.Tensor(9.154351, shape=(), dtype=float32)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "a = tf.constant([[[0.25106466, 0.00863039, 0.77634084, 0.23125434, 0.39757788],\n",
    "  [0.82858,    0.44247448, 0.9647038,  0.31152928, 0.7297981 ]],\n",
    " [[0.8109468,  0.4998417,  0.31938195 ,0.03625381 ,0.92246723],\n",
    "  [0.03745341, 0.7016275,  0.58033264, 0.10916102, 0.7598084 ]],\n",
    " [[0.57786167, 0.48389828, 0.7559997 , 0.51311195, 0.3556137 ],\n",
    "  [0.06377017, 0.37903416, 0.69512844, 0.8320352 , 0.3528793 ]]])\n",
    "b = tf.constant([[[0.25106466, 0.00863039, 0.77634084, 0.23125434, 0.39757788],\n",
    "  [0.82858,    0.44247448, 0.9647038,  0.31152928, 0.7297981 ]],\n",
    " [[0.8109468,  0.4998417,  0.31938195 ,0.03625381 ,0.92246723],\n",
    "  [0.03745341, 0.7016275,  0.58033264, 0.10916102, 0.7598084 ]],\n",
    " [[0.57786167, 0.48389828, 0.7559997 , 0.51311195, 0.3556137 ],\n",
    "  [0.06377017, 0.37903416, 0.69512844, 0.8320352 , 0.3528793 ]]])\n",
    "\n",
    "# print(a)\n",
    "# print(b)\n",
    "l = xentropy_loss(a,b)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def grad(model: tf.keras.Model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = xentropy_loss(model(inputs), targets, training=True)\n",
    "  return loss_value, tape.gradient(loss_value, model.trainable_variables)   \n",
    "\n",
    "def train(epoch, train_dataset: tf.data.Dataset, model: tf.keras.Model, optimizer):\n",
    "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "  epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "  # Training loop - using batches of 32\n",
    "  for x, y in train_dataset:\n",
    "    # Optimize the model\n",
    "    loss_value, grads = grad(model, x, y)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    # Track progress\n",
    "    epoch_loss_avg(loss_value)  # Add current batch loss\n",
    "    # Compare predicted label to actual label\n",
    "    # training=True is needed only if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    epoch_accuracy(y, model(x, training=True))\n",
    "\n",
    "  # # End epoch\n",
    "  # train_loss_results.append(epoch_loss_avg.result())\n",
    "  # train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "  if epoch % 50 == 0:\n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                                epoch_loss_avg.result(),\n",
    "                                                                epoch_accuracy.result()))   \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "importlib.reload(fashion_enc)\n",
    "\n",
    "params = misc.get_model_params(\"base\", 1)\n",
    "\n",
    "params.update({\n",
    "    \"feature_dim\": 512,\n",
    "    \"dtype\": \"float32\",\n",
    "    \"hidden_size\": 512,\n",
    "    \"extra_decode_length\": 0,\n",
    "    \"num_hidden_layers\": 1,\n",
    "    \"num_heads\": 2,\n",
    "    \"max_length\": 10,\n",
    "    \"default_batch_size\": 128,\n",
    "    \"filter_size\": 1024\n",
    "})\n",
    "\n",
    "model = fashion_enc.create_model(params, False)\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}